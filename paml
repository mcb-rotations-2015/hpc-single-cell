#!/bin/bash

# PAML [1] is a single-threaded program for phylogenetic analysis.
# Therefore, to parallelize it, we use GNU Parallel.
#
# [1] abacus.gene.ucl.ac.uk/software/paml.html

function usage() {
    echo "Usage: paml --file TSV_FILE --directory DIR_NAME [--dryrun]"
    echo ""
    echo "Parameters:"
    echo "-f --file       File with list of datasets to process."
    echo "-d --directory  Relative prefix containing the datasets."
    echo "--dryrun        Print the job to run on stdout, but do not run the job."
}

if [[ $# -eq 0 ]]; then
    usage
    exit 1
fi

# Parse all arguments.
# 
while [[ $# > 0 ]]; do
    case "$1" in
	-f|--file) TSV_FILE="$2"; shift 2;;
	-d|--directory) DIR_NAME="$2"; shift 2;;
	--dryrun) DRYRUN=1; shift;;
	*) usage
	   exit 1;;
    esac
done

# Name the parallel joblog file according to the input file name.
# Like a Makefile, a joblog prevents multiple runs of the same task,
# as well as logging excellent statistics about each task, which we
# can check while the job is running with `tail -f JOBLOG`.
#
tsv_basename=$(basename ${TSV_FILE}) # Remove directories from tsv_file
joblog_name="${tsv_basename%%.*}"     # Strip the extension

# Optimize for the 16 cores and 128 GB RAM on Ivy Bridge on UConn's
# BECAT cluster [1].  The delay is to allow enough time for initial memory
# allocation.
# 
# [1] http://www.becat.uconn.edu/wiki/index.php/HPC_Getting_Started#Overview_of_cluster_nodes
#
parallel="parallel
 --memfree 5G
 --header :
"
if [ -n "${DRYRUN}" ]; then
    dryrun_tsv_file=dryrun-snippet-$(basename ${TSV_FILE})
    head ${TSV_FILE} > ${dryrun_tsv_file}
    parallel="${parallel}
 --dryrun
 --arg-file ${dryrun_tsv_file}
"
else
    parallel="${parallel}
 --arg-file ${TSV_FILE}
 --joblog log/parallel-${joblog_name}-paml.log
 --resume-failed
"
fi

# Make the assumption that the DATA_DIR is at the root of the
# TSV_FILE directory.
# 
data_dir_prefix=$(dirname ${TSV_FILE})/${DIR_NAME}

# We get the {family} column from tsv_file using parallel's
# `--header`.  Basically, `parallel --header : --arg-file FILE COMMAND
# {HEADER_NAME}` does the job of `cut` in the shell, but it is
# infinitely nicer since it uses named fields.
#
data_file_prefix="${data_dir_prefix}/{family}/{family}"

# Find the required dependencies
# 
export codeml_bin=codeml
export codeml_ctl=codeml.ctl
export clustalw_bin=clustalw2
bundled_bin=3rdparty/paml/paml4.8/bin/${codeml_bin}
bundled_ctl=3rdparty/paml/paml4.8/${codeml_ctl}
bundled_clustalw=3rdparty/clustalw/bin/${clustalw_bin}
if ! [ -e "${codeml_bin}" ]; then
    codeml_bin=${bundled_bin}
    codeml_ctl=${bundled_ctl}
fi
if ! [ -e "${codeml_bin}" ]; then
    echo "Error: Please fetch and compile codeml and codeml.ctl using 'make deps'"
    exit 1
fi
if ! [ -e "${clustalw_bin}" ]; then
    clustalw_bin=${bundled_clustalw}
fi
if ! [ -e "${clustalw_bin}" ]; then
    echo "Error: Please fetch and compile clustalw using 'make deps'"
    exit 1
fi

# Write the input control file and run codeml on it
# 
# Globals: codeml_ctl, codeml_bin, clustalw_bin
# Arguments: 
#   $1: dataset path with dataset basename
# Returns: None
# 
function paml_tasks() {
    # Assign the control file variables
    seq_file=$1.phylip
    tree_file=$1.tree.paml
    out_file=$1.paml.out
    ctl_file=$1.ctl
    # Write the control file for codeml
    sed -r \
	-e "s#(seqfile = ).*#\1${seq_file}#" \
	-e "s#(treefile = ).*#\1${tree_file}#" \
	-e "s#(outfile = ).*#\1${out_file}#" \
	${codeml_ctl} > ${ctl_file}
    # Convert macse fasta file to interleaved phylip
    macse_seq_file=$1_pa.fasta_macse_NT.fasta
    ${clustalw_bin} \
	-INFILE=${macse_seq_file} \
	-CONVERT \
	-OUTPUT=PHYLIP \
	-OUTFILE=${seq_file}
    # Run codeml pseudo-interactively
    script -c "${codeml_bin}" ${ctl_file}
    #${codeml_bin} ${ctl_file}
}
export -f paml_tasks

# Run all the things!
#
logs_dir=log/${joblog_name}
mkdir -p ${logs_dir}
${parallel} paml_tasks ${data_file_prefix} "> ${logs_dir}/{#}-paml-{family}.log 2>&1"
