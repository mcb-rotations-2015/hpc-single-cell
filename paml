#!/bin/bash

# PAML [1] is a single-threaded program for phylogenetic analysis.
# Therefore, to parallelize it, we use GNU Parallel.
#
# [1] abacus.gene.ucl.ac.uk/software/paml.html

function usage() {
    echo "Usage: paml --file TSV_FILE --directory DIR_NAME [--dryrun]"
    echo ""
    echo "Parameters:"
    echo "-f --file       File with list of datasets to process."
    echo "-d --directory  Relative prefix containing the datasets."
    echo "--dryrun        Print the job to run on stdout, but do not run the job."
}

if [[ $# -eq 0 ]]; then
    usage
    exit 1
fi

# Parse all arguments.
# 
while [[ $# > 0 ]]; do
    case "$1" in
	-f|--file) TSV_FILE="$2"; shift 2;;
	-d|--directory) DIR_NAME="$2"; shift 2;;
	--dryrun) DRYRUN=1; shift;;
	*) usage
	   exit 1;;
    esac
done

# Name the parallel joblog file according to the input file name.
# Like a Makefile, a joblog prevents multiple runs of the same task,
# as well as logging excellent statistics about each task, which we
# can check while the job is running with `tail -f JOBLOG`.
#
tsv_basename=$(basename ${TSV_FILE}) # Remove directories from tsv_file
tsv_no_ext="${tsv_basename%%.*}"     # Strip the extension

# Optimize for the 16 cores and 128 GB RAM on Ivy Bridge on UConn's
# BECAT cluster [1].  The delay is to allow enough time for initial memory
# allocation.
# 
# [1] http://www.becat.uconn.edu/wiki/index.php/HPC_Getting_Started#Overview_of_cluster_nodes
#
parallel="parallel
 --memfree 5G
 --header :
"
if [ -n "${DRYRUN}" ]; then
    dryrun_tsv_file=dryrun-snippet-$(basename ${TSV_FILE})
    head ${TSV_FILE} > ${dryrun_tsv_file}
    parallel="${parallel}
 --dryrun
 --arg-file ${dryrun_tsv_file}
"
else
    parallel="${parallel}
 --arg-file ${TSV_FILE}
 --joblog parallel-${tsv_no_ext}-paml.log
 --resume-failed
"
fi

# Make the assumption that the DATA_DIR is at the root of the
# TSV_FILE directory.
# 
data_dir_prefix=$(dirname ${TSV_FILE})/${DIR_NAME}

# We get the {family} column from tsv_file using parallel's
# `--header`.  Basically, `parallel --header : --arg-file FILE COMMAND
# {HEADER_NAME}` does the job of `cut` in the shell, but it is
# infinitely nicer since it uses named fields.
#
data_file_prefix="${data_dir_prefix}/{family}/{family}"

# Find the required dependencies
# 
codeml_bin=codeml
codeml_ctl=codeml.ctl
clustlw_bin=clustalw2
bundled_bin=3rdparty/paml/paml4.8/bin/${codeml_bin}
bundled_ctl=3rdparty/paml/paml4.8/${codeml_ctl}
bundled_clustlw=3rdparty/clustalw/bin/${clustlw_bin}
if ! [ -e "${codeml_bin}" ]; then
    codeml_bin=${bundled_bin}
    codeml_ctl=${bundled_ctl}
fi
if ! [ -e "${codeml_bin}" ]; then
    echo "Error: Please fetch and compile codeml and codeml.ctl using 'make deps'"
    exit 1
fi
if ! [ -e "${clustlw_bin}" ]; then
    clustlw_bin=${bundled_clustlw}
fi
if ! [ -e "${clustlw_bin}" ]; then
    echo "Error: Please fetch and compile clustlw using 'make deps'"
    exit 1
fi

# Write the input control file and run codeml on it
# 
# Globals: codeml_ctl, dataprefix
# Arguments: 
#   $1: dataset path with dataset basename
# Returns: None
# 
function paml_tasks() {
    # Assign the control file variables
    dataset=$(basename $1)
    seq_file=${dataset}.phylip
    tree_file=${dataset}.tree.paml
    out_file=${dataset}.paml.out
    ctl_file=$1.ctl
    # Write the control file for codeml, prepending 3 lines
    echo "seqfile = ${seq_file}
treefile = ${tree_file}
outfile = ${out_file}" | cat - ${codeml_ctl} > ${ctl_file}
    # Convert macse fasta file to interleaved phylip
    macse_seq_file=$1_pa.fasta_macse_NT.fasta
    ${clustlw} \
	-INFILE=${macse_seq_file} \
	-CONVERT \
	-OUTPUT=PHYLIP \
	-OUTFILE=${seq_file}
    # Run codeml
    ${codeml_bin} ${ctl_file}
}
export -f paml_tasks

# Run all the things!
#
mkdir -p ${tsv_no_ext}
${parallel} paml_tasks ${data_file_prefix} "> ${tsv_no_ext}/{#}-paml-{family}.log"
